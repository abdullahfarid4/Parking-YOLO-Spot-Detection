{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "910cf68a",
      "metadata": {
        "id": "910cf68a"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "from scipy.cluster.vq import whiten, kmeans, vq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17b184cc",
      "metadata": {
        "id": "17b184cc"
      },
      "outputs": [],
      "source": [
        "def parking(image_path, output_full_image_path, model_weights_path, input_width, input_height, offset, confidence, class_score):\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    img = cv2.resize(img, (640, 640), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    net = cv2.dnn.readNetFromONNX(model_weights_path)\n",
        "    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
        "    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
        "\n",
        "    image = img.copy()\n",
        "    row, col, d = image.shape\n",
        "\n",
        "    max_rc = max(row, col)\n",
        "    input_image = np.zeros((max_rc, max_rc, 3), dtype = np.uint8)\n",
        "    input_image[0:row, 0:col] = image\n",
        "\n",
        "    blob = cv2.dnn.blobFromImage(input_image, 1 / 255, (input_width, input_height), swapRB = True, crop = False)\n",
        "    net.setInput(blob)\n",
        "    preds = net.forward()\n",
        "    detections = preds[0]\n",
        "\n",
        "    centering_gap = offset\n",
        "\n",
        "    empty, empty_boxes = bounding_box(input_image, detections, 5, confidence, input_width, input_height, class_score)\n",
        "    occupied, occupied_boxes = bounding_box(input_image, detections, 6, confidence, input_width, input_height, class_score)\n",
        "\n",
        "    x_empty, y_empty, w_empty, h_empty = draw_bounding_boxes(image, output_full_image_path, empty, empty_boxes, centering_gap, (0, 0, 255))\n",
        "    x_occupied, y_occupied, w_occupied, h_occupied = draw_bounding_boxes(image, output_full_image_path, occupied, occupied_boxes, centering_gap, (0, 255, 0))\n",
        "\n",
        "    df_empty = pd.DataFrame(columns = ['index', 'X', 'Y', 'W', 'H', 'Status', 'Color'])\n",
        "    df_occupied = pd.DataFrame(columns = ['index', 'X', 'Y', 'W', 'H', 'Status', 'Color'])\n",
        "\n",
        "    df_empty['X'], df_empty['Y'], df_empty['W'], df_empty['H'], df_empty['Status'] =  x_empty, y_empty, w_empty, h_empty, 'Empty'\n",
        "    df_occupied['X'], df_occupied['Y'], df_occupied['W'], df_occupied['H'], df_occupied['Status'] =  x_occupied, y_occupied, w_occupied, h_occupied , 'Occupied'\n",
        "\n",
        "    ranked_y = rank_numbers(y_empty + y_occupied)\n",
        "    ranked_x = rank_numbers(x_empty + x_occupied)\n",
        "\n",
        "    df_full = pd.concat([df_empty, df_occupied])\n",
        "    df_full['Y_rank'] = ranked_y\n",
        "    df_full['X_rank'] = ranked_x\n",
        "\n",
        "    df_full = df_full.sort_values(['Y_rank', 'X_rank'])\n",
        "    df_full['Spot Number'] = [x + 1 for x in list(range(df_full.shape[0]))]\n",
        "\n",
        "    for i in range(len(x_occupied)):\n",
        "        string = \"test\" + str(i) + \".jpg\"\n",
        "        cv2.imwrite(string, img[y_occupied[i] - centering_gap: y_occupied[i] + h_occupied[i] - centering_gap, x_occupied[i] : x_occupied[i] + w_occupied[i]])\n",
        "\n",
        "    lst = []\n",
        "\n",
        "    for i in range(len(x_occupied)):\n",
        "        input_image_path = \"test\" + str(i) + \".jpg\"\n",
        "        output_image_path = \"test\" + str(i) + \".jpg\"\n",
        "        # new_width = w_occupied[i] * 10\n",
        "        # new_height = h_occupied[i] * 10\n",
        "        new_width = w_occupied[i]\n",
        "        new_height = h_occupied[i]\n",
        "\n",
        "        resize_image(input_image_path, output_image_path, new_width, new_height)\n",
        "\n",
        "        color = car_color(output_image_path)\n",
        "        lst.append(color)\n",
        "\n",
        "    lst = [str(x) for x in lst]\n",
        "    df_full.loc[df_full['Status'] == 'Occupied', 'Color'] = lst\n",
        "    df_full.to_csv('Parking Spots Details.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parking(image_path, output_full_image_path, model_weights_path, input_width, input_height, offset, confidence, class_score, csv_file):\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    img = cv2.resize(img, (640, 640), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    net = cv2.dnn.readNetFromONNX(model_weights_path)\n",
        "    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
        "    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
        "\n",
        "    image = img.copy()\n",
        "    row, col, d = image.shape\n",
        "\n",
        "    max_rc = max(row, col)\n",
        "    input_image = np.zeros((max_rc, max_rc, 3), dtype = np.uint8)\n",
        "    input_image[0:row, 0:col] = image\n",
        "\n",
        "    blob = cv2.dnn.blobFromImage(input_image, 1 / 255, (input_width, input_height), swapRB = True, crop = False)\n",
        "    net.setInput(blob)\n",
        "    preds = net.forward()\n",
        "    detections = preds[0]\n",
        "\n",
        "    centering_gap = offset\n",
        "\n",
        "    empty, empty_boxes = bounding_box(input_image, detections, 5, confidence, input_width, input_height, class_score)\n",
        "    occupied, occupied_boxes = bounding_box(input_image, detections, 6, confidence, input_width, input_height, class_score)\n",
        "\n",
        "    x_empty, y_empty, w_empty, h_empty = draw_bounding_boxes(image, output_full_image_path, empty, empty_boxes, centering_gap, (0, 0, 255))\n",
        "    x_occupied, y_occupied, w_occupied, h_occupied = draw_bounding_boxes(image, output_full_image_path, occupied, occupied_boxes, centering_gap, (0, 255, 0))\n",
        "\n",
        "    df_empty = pd.DataFrame(columns = ['index', 'X', 'Y', 'W', 'H', 'Status', 'Color'])\n",
        "    df_occupied = pd.DataFrame(columns = ['index', 'X', 'Y', 'W', 'H', 'Status', 'Color'])\n",
        "\n",
        "    df_empty['X'], df_empty['Y'], df_empty['W'], df_empty['H'], df_empty['Status'] =  x_empty, y_empty, w_empty, h_empty, 'Empty'\n",
        "    df_occupied['X'], df_occupied['Y'], df_occupied['W'], df_occupied['H'], df_occupied['Status'] =  x_occupied, y_occupied, w_occupied, h_occupied , 'Occupied'\n",
        "\n",
        "    ranked_y = rank_numbers(y_empty + y_occupied)\n",
        "    ranked_x = rank_numbers(x_empty + x_occupied)\n",
        "\n",
        "    df_full = pd.concat([df_empty, df_occupied])\n",
        "    df_full['Y_rank'] = ranked_y\n",
        "    df_full['X_rank'] = ranked_x\n",
        "\n",
        "    df_full = df_full.sort_values(['Y_rank', 'X_rank'])\n",
        "    df_full['Spot Number'] = [x + 1 for x in list(range(df_full.shape[0]))]\n",
        "\n",
        "    for i in range(len(x_occupied)):\n",
        "        string = \"test\" + str(i) + \".jpg\"\n",
        "        cv2.imwrite(string, img[y_occupied[i] - centering_gap: y_occupied[i] + h_occupied[i] - centering_gap, x_occupied[i] : x_occupied[i] + w_occupied[i]])\n",
        "\n",
        "    lst = []\n",
        "\n",
        "    for i in range(len(x_occupied)):\n",
        "        input_image_path = \"test\" + str(i) + \".jpg\"\n",
        "        output_image_path = \"test\" + str(i) + \".jpg\"\n",
        "        # new_width = w_occupied[i] * 10\n",
        "        # new_height = h_occupied[i] * 10\n",
        "        new_width = w_occupied[i]\n",
        "        new_height = h_occupied[i]\n",
        "\n",
        "        resize_image(input_image_path, output_image_path, new_width, new_height)\n",
        "\n",
        "        color = car_color(output_image_path)\n",
        "        lst.append(color)\n",
        "\n",
        "    lst = [str(x) for x in lst]\n",
        "    df_full.loc[df_full['Status'] == 'Occupied', 'Color'] = lst\n",
        "    df_full.to_csv(csv_file, index=False)"
      ],
      "metadata": {
        "id": "F1HZUIvh78zD"
      },
      "id": "F1HZUIvh78zD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c60b5c4",
      "metadata": {
        "id": "1c60b5c4"
      },
      "outputs": [],
      "source": [
        "def bounding_box(input_image, detections, spot_class, confidence_thresh, input_width, input_height, score):\n",
        "    boxes = []\n",
        "    confidences = []\n",
        "\n",
        "    image_w, image_h = input_image.shape[:2]\n",
        "    x_factor = image_w / input_width\n",
        "    y_factor = image_h / input_height\n",
        "\n",
        "    for i in range(len(detections)):\n",
        "        row = detections[i]\n",
        "        confidence = row[4]\n",
        "        if confidence > confidence_thresh:\n",
        "            class_score = row[spot_class]\n",
        "            if class_score > score:\n",
        "                cx, cy, w, h = row[0:4]\n",
        "\n",
        "                left = int((cx - 0.5 * w) * x_factor)\n",
        "                top = int((cy - 0.5) * y_factor)\n",
        "                width = int(w * x_factor)\n",
        "                height = int(h * y_factor)\n",
        "                box = np.array([left, top, width, height])\n",
        "\n",
        "                confidences.append(confidence)\n",
        "                boxes.append(box)\n",
        "\n",
        "    boxes_np = np.array(boxes).tolist()\n",
        "    confidences_np = np.array(confidences).tolist()\n",
        "\n",
        "    index = cv2.dnn.NMSBoxes(boxes_np, confidences_np, score, confidence_thresh)\n",
        "\n",
        "    return index, boxes_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb9478c3",
      "metadata": {
        "id": "cb9478c3"
      },
      "outputs": [],
      "source": [
        "def draw_bounding_boxes(image, out_img_path, class_spot, boxes_np, centering_gap, rgb):\n",
        "    x_list = []\n",
        "    y_list = []\n",
        "    w_list = []\n",
        "    h_list = []\n",
        "\n",
        "    for ind in class_spot:\n",
        "        x, y, w, h = boxes_np[ind]\n",
        "        x_list.append(x)\n",
        "        y_list.append(y)\n",
        "        w_list.append(w)\n",
        "        h_list.append(h)\n",
        "\n",
        "        cv2.rectangle(image, (x, y - centering_gap), (x + w, y + h - centering_gap), rgb, 1)\n",
        "\n",
        "    cv2.imwrite(out_img_path, image)\n",
        "\n",
        "    return x_list, y_list, w_list, h_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96edb139",
      "metadata": {
        "id": "96edb139"
      },
      "outputs": [],
      "source": [
        "def rank_numbers(unsorted_numbers):\n",
        "    # Sort the original list\n",
        "    sorted_numbers = sorted(unsorted_numbers)\n",
        "\n",
        "    # Create a dictionary to store the rank of each number\n",
        "    ranks = {}\n",
        "    rank = 1\n",
        "    for num in sorted_numbers:\n",
        "        # If the number is not already in the dictionary, add it with its rank\n",
        "        if num not in ranks:\n",
        "            ranks[num] = rank\n",
        "            rank += 1\n",
        "\n",
        "    # Create a list of ranks corresponding to the original unsorted numbers\n",
        "    ranked_list = [ranks[num] for num in unsorted_numbers]\n",
        "\n",
        "    return ranked_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a48215f2",
      "metadata": {
        "id": "a48215f2"
      },
      "outputs": [],
      "source": [
        "def resize_image(input_image_path, output_image_path, new_width, new_height):\n",
        "    original_image = Image.open(input_image_path)\n",
        "    resized_image = original_image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
        "    resized_image.save(output_image_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# from sklearn.cluster import KMeans\n",
        "\n",
        "# def car_color(car_path):\n",
        "#   car_image = img.imread(car_path)\n",
        "\n",
        "#   # Reshape and convert to float for faster operations\n",
        "#   pixels = car_image.reshape(-1, 3).astype(np.float64)\n",
        "\n",
        "#   # Whiten color values directly in-place (avoid DataFrame creation)\n",
        "#   pixels[:, 0] = whiten(pixels[:, 0])\n",
        "#   pixels[:, 1] = whiten(pixels[:, 1])\n",
        "#   pixels[:, 2] = whiten(pixels[:, 2])\n",
        "\n",
        "#   # Calculate standard deviation directly from the array (no DataFrame needed)\n",
        "#   r_std, g_std, b_std = pixels.std(axis=0)\n",
        "\n",
        "#   # Perform k-means clustering directly on the array\n",
        "#   kmeans = KMeans(n_clusters=2)\n",
        "#   kmeans.fit(pixels)\n",
        "#   cluster_centers = kmeans.cluster_centers_\n",
        "\n",
        "#   # Convert scaled centers to original colors (avoid list conversions)\n",
        "#   colors = (cluster_centers * np.array([r_std, g_std, b_std]) / 255)\n",
        "#   colors = np.clip(colors, 0, 1) * 255\n",
        "#   colors = colors.astype(int).tolist()\n",
        "\n",
        "#   return colors"
      ],
      "metadata": {
        "id": "teMJHHF_Rgp-"
      },
      "id": "teMJHHF_Rgp-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # import numpy as np\n",
        "# # import pandas as pd\n",
        "# # from scipy.cluster.vq import whiten, kmeans\n",
        "# # from matplotlib import image as img\n",
        "\n",
        "# def car_color(car_path):\n",
        "#     car_image = img.imread(car_path)\n",
        "\n",
        "#     # Flatten the image array and separate the color channels\n",
        "#     pixels = car_image.reshape(-1, 3)\n",
        "#     r, g, b = pixels[:, 0], pixels[:, 1], pixels[:, 2]\n",
        "\n",
        "#     # Create a DataFrame and whiten the color values\n",
        "#     colors_df = pd.DataFrame({'red': r, 'blue': b, 'green': g})\n",
        "#     colors_df['scaled_red'] = whiten(r)\n",
        "#     colors_df['scaled_blue'] = whiten(b)\n",
        "#     colors_df['scaled_green'] = whiten(g)\n",
        "\n",
        "#     r_std, g_std, b_std = colors_df[['red', 'green', 'blue']].std()\n",
        "\n",
        "#     # Perform k-means clustering\n",
        "#     n_cluster = 2\n",
        "#     cluster_centers, _ = kmeans(colors_df[['scaled_red', 'scaled_blue', 'scaled_green']], n_cluster)\n",
        "\n",
        "#     # Convert scaled cluster centers back to original color values\n",
        "#     colors = (cluster_centers * [r_std, g_std, b_std] / 255).tolist()\n",
        "#     colors = np.clip(colors, 0, 1) * 255\n",
        "#     colors = np.array(colors).astype(int).tolist()\n",
        "\n",
        "#     return colors\n",
        "\n",
        "# Usage\n",
        "# car_path = 'path_to_your_image.jpg'\n",
        "# colors = process_image(car_path)\n",
        "# print(colors)\n"
      ],
      "metadata": {
        "id": "RTxXCUXc-qz8"
      },
      "id": "RTxXCUXc-qz8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def car_color(car_path):\n",
        "    car_image = img.imread(car_path)\n",
        "    height, width, _ = car_image.shape\n",
        "    car_image = car_image[:height-20, :]\n",
        "\n",
        "    # Flatten the image array and separate the color channels\n",
        "    pixels = car_image.reshape(-1, 3)\n",
        "    r, g, b = pixels[:, 0], pixels[:, 1], pixels[:, 2]\n",
        "\n",
        "    # Create a DataFrame and whiten the color values\n",
        "    colors_df = pd.DataFrame({'red': r, 'blue': b, 'green': g})\n",
        "    colors_df['scaled_red'] = whiten(r)\n",
        "    colors_df['scaled_blue'] = whiten(b)\n",
        "    colors_df['scaled_green'] = whiten(g)\n",
        "\n",
        "    r_std, g_std, b_std = colors_df[['red', 'green', 'blue']].std()\n",
        "\n",
        "    # Perform k-means clustering\n",
        "    n_cluster = 3\n",
        "    cluster_centers, _ = kmeans(colors_df[['scaled_red', 'scaled_blue', 'scaled_green']], n_cluster)\n",
        "    cluster_labels, _ = vq(colors_df[['scaled_red', 'scaled_blue', 'scaled_green']], cluster_centers)\n",
        "    counts = np.bincount(cluster_labels)\n",
        "\n",
        "    # Identify the biggest cluster\n",
        "    sorted_indices = np.argsort(counts)[::-1]\n",
        "    second_largest_cluster_index = sorted_indices[1]\n",
        "    second_largest_cluster_size = counts[second_largest_cluster_index]\n",
        "\n",
        "    # Convert scaled cluster centers back to original color values\n",
        "    colors = (cluster_centers * [r_std, g_std, b_std] / 255).tolist()\n",
        "    colors = np.clip(colors, 0, 1) * 255\n",
        "    colors = np.array(colors).astype(int).tolist()\n",
        "\n",
        "    return colors[second_largest_cluster_index]"
      ],
      "metadata": {
        "id": "xXe-yqenOruz"
      },
      "id": "xXe-yqenOruz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99bc047d",
      "metadata": {
        "id": "99bc047d"
      },
      "outputs": [],
      "source": [
        "# def car_color(car_path):\n",
        "#     car_image = img.imread(car_path)\n",
        "\n",
        "#     r, g, b = [], [], []\n",
        "\n",
        "#     for row in car_image:\n",
        "#         for temp_r, temp_g, temp_b in row:\n",
        "#             r.append(temp_r)\n",
        "#             g.append(temp_g)\n",
        "#             b.append(temp_b)\n",
        "\n",
        "#     colors_df = pd.DataFrame({'red': r, 'blue': b, 'green': g,\n",
        "#                               'scaled_red': whiten(r), 'scaled_blue': whiten(b), 'scaled_green': whiten(g)})\n",
        "\n",
        "#     r_std, g_std, b_std = colors_df[['red', 'green', 'blue']].std()\n",
        "\n",
        "#     colors = []\n",
        "\n",
        "#     n_cluster = 2\n",
        "#     cluster_centers, _ = kmeans(colors_df[['scaled_red', 'scaled_blue', 'scaled_green']], n_cluster)\n",
        "\n",
        "#     for cluster_center in cluster_centers:\n",
        "#         scaled_r, scaled_g, scaled_b = cluster_center\n",
        "#         colors.append((scaled_r * r_std / 255, scaled_g * g_std / 255, scaled_b * b_std / 255))\n",
        "\n",
        "#     colors2 = np.array(colors)\n",
        "\n",
        "#     has_one = np.any(colors2 > 1, axis=1)\n",
        "\n",
        "#     for i, row_has_one in enumerate(has_one):\n",
        "#         if row_has_one:\n",
        "#             maxi = np.max(colors2, axis = 1).reshape(-1, 1)\n",
        "#             colors2[i] = colors2[i] * (255 / maxi[i])\n",
        "#         else:\n",
        "#             colors2[i] = colors2[i] * 255\n",
        "\n",
        "#     for i in range(0, n_cluster):\n",
        "#         colors[i] = colors2[i].astype('int').tolist()\n",
        "\n",
        "#     return list(colors)\n",
        "\n",
        "# #     # plt.imshow(car_image)\n",
        "# #     # plt.show()\n",
        "\n",
        "# #     # plt.imshow([colors])\n",
        "# #     # plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 11):\n",
        "  parking('/content/a (' + str(i) + ').jpg',\n",
        "        'img_w_boxes'+ str(i) + '.jpg',\n",
        "        '/content/best (3).onnx',\n",
        "        640,\n",
        "        640,\n",
        "        40,\n",
        "        0.35,\n",
        "        0.6)"
      ],
      "metadata": {
        "id": "OQgYv-Qa6EOY"
      },
      "id": "OQgYv-Qa6EOY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "parking('/2012-09-11_15_16_58_jpg.rf.db6b964cc73d426741e1e15e48f81120.jpg',\n",
        "        'img_w_boxes.jpg',\n",
        "        '/best (2).onnx',\n",
        "        640,\n",
        "        640,\n",
        "        20,\n",
        "        0.4,\n",
        "        0.25,\n",
        "        'RealParking.csv')"
      ],
      "metadata": {
        "id": "WqREjl3SlHlV"
      },
      "id": "WqREjl3SlHlV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parking('/content/2012-11-10_14_53_02_jpg.rf.4872e8942e72b9496cb0676aa53a971b.jpg',\n",
        "        '/content/img_w_boxes.jpg',\n",
        "        '/content/best.onnx',\n",
        "        640,\n",
        "        640,\n",
        "        20,\n",
        "        0.4,\n",
        "        0.25,\n",
        "        'RealParking.csv')"
      ],
      "metadata": {
        "id": "z969Bstevi90"
      },
      "id": "z969Bstevi90",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parking('/content/msg1723932588-2012.jpg',\n",
        "        'img_w_boxes.jpg',\n",
        "        '/content/best (3).onnx',\n",
        "        640,\n",
        "        640,\n",
        "        40,\n",
        "        0.35,\n",
        "        0.7,\n",
        "        'Parking.csv')"
      ],
      "metadata": {
        "id": "YFw7Ud_BoG-R"
      },
      "id": "YFw7Ud_BoG-R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(101, 134):\n",
        "  parking('/content/a (' + str(i) + ').jpg',\n",
        "        'img_w_boxes' + str(i) + '.jpg',\n",
        "        '/content/best (3).onnx',\n",
        "        640,\n",
        "        640,\n",
        "        40,\n",
        "        0.35,\n",
        "        0.7,\n",
        "        'Parking' + str(i) + '.csv')\n",
        "  print(i, end='-rows: ')\n",
        "  df = pd.read_csv('Parking' + str(i) + '.csv')\n",
        "  print(df.shape[0])"
      ],
      "metadata": {
        "id": "xmrVpVC8zdvF"
      },
      "id": "xmrVpVC8zdvF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gsu9ityDkACa"
      },
      "id": "Gsu9ityDkACa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fwHp9V0ej_2y"
      },
      "id": "fwHp9V0ej_2y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fCBMfZFlj_er"
      },
      "id": "fCBMfZFlj_er",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parking('/content/Untitled.jpeg',\n",
        "#         'img_w_boxes2.jpg',\n",
        "#         '/content/best.onnx',\n",
        "#         640,\n",
        "#         640,\n",
        "#         20,\n",
        "#         0.3,\n",
        "#         0.1)"
      ],
      "metadata": {
        "id": "aJP7d0wg68tn"
      },
      "id": "aJP7d0wg68tn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7NXnItKuLYH2"
      },
      "id": "7NXnItKuLYH2",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}